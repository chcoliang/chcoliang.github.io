---
permalink: /zh
title: "é™ˆæ·™é“"
excerpt: ""
author_profile: true
navigation_data: navigation_zh
redirect_from: 
  - /about/
  - /about_zh.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ğŸ§‘â€ğŸ“ å…³äºæˆ‘

æˆ‘æ˜¯é™ˆæ·™é“ã€‚ æˆ‘æœ¬ç§‘æ¯•ä¸šäºåŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢ï¼Œåšå£«æ¯•ä¸šäºé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰ï¼Œå¯¼å¸ˆä¸º[ç½—æ™ºæ³‰æ•™æˆ](https://tomluo123.github.io/)ã€‚ç›®å‰ï¼Œæˆ‘åœ¨æ·±åœ³æ²³å¥—å­¦é™¢æ‹…ä»»ç ”ç©¶åŠ©ç†æ•™æˆã€‚æˆ‘çš„ç ”ç©¶æ–¹å‘ä¸»è¦åŒ…æ‹¬æ•°å€¼è®¡ç®—ã€å¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–ç®—æ³•ï¼Œä»¥åŠç®—å­ç”Ÿæˆä¸ä¼˜åŒ–ã€‚

æˆ‘åœ¨åˆ†å¸ƒå¼ Adam æ–¹é¢çš„å·¥ä½œè¯æ˜äº†å…¶åœ¨å¤šæœºè®­ç»ƒåœºæ™¯ä¸‹çš„ç†è®ºåŠ é€Ÿæ•ˆæœï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šä¿¡é«˜æ•ˆçš„ Adam å˜ä½“ï¼Œä½¿å¾—ç¥ç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­æ¯è½®æ¯ä¸ªå‚æ•°ä»…éœ€ 1 bit çš„é€šä¿¡å¼€é”€ã€‚æˆ‘ä¹Ÿå‚ä¸äº† Adam-mini çš„ç ”ç©¶ï¼Œè¯¥æ–¹æ³•æ˜¯ä¸€ç§è½»é‡ä¸”å®ç”¨çš„ä¼˜åŒ–å™¨å˜ä½“ï¼Œé¢å‘å¤§è§„æ¨¡è®­ç»ƒçš„é«˜æ•ˆéœ€æ±‚ã€‚æ­¤å¤–ï¼Œæˆ‘è¿˜å‚ä¸äº† GEM å·¥ä½œï¼Œç ”ç©¶å¦‚ä½•åœ¨å¤§æ¨¡å‹ç›‘ç£å¾®è°ƒè¿‡ç¨‹ä¸­ä¿æŒè¾“å‡ºå¤šæ ·æ€§ï¼Œä»¥ç¼“è§£æ¨¡å¼åå¡Œå¹¶æå‡æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘çš„ç ”ç©¶æˆæœå‘è¡¨äº JMLRã€IEEE TSP ç­‰æœŸåˆŠä»¥åŠ NeurIPSã€ICLR ç­‰é¡¶çº§å›½é™…ä¼šè®®ï¼Œ<a href='https://scholar.google.com/citations?user=O1P1-EAAAAA'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>ã€‚


**æ‹›å‹Ÿä¿¡æ¯**ï¼šæˆ‘ä»¬æ­£åœ¨æ‹›å‹Ÿ**ç ”ç©¶åŠ©ç†ï¼ˆResearch Assistant**å’Œ**åšå£«ç”Ÿ**ï¼Œç ”ç©¶æ–¹å‘åŒ…æ‹¬å¤§æ¨¡å‹ä¼˜åŒ–ä»¥åŠç®—å­ç”Ÿæˆä¸ä¼˜åŒ–ã€‚

ç ”ç©¶ä¸»é¢˜åŒ…æ‹¬ï¼š

- å¤§è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–ç®—æ³•

- ç®—å­ç”Ÿæˆä¸æ€§èƒ½ä¼˜åŒ–

å¦‚æœ‰å…´è¶£ï¼Œè¯·å‘é€é‚®ä»¶å¹¶é™„ä¸Šï¼šï¼ˆ1ï¼‰ä¸ªäººç®€å†ï¼ˆCVï¼‰ï¼Œï¼ˆ2ï¼‰ç®€è¦çš„ç§‘ç ”/å·¥ç¨‹ç»å†ä»‹ç»ï¼Œï¼ˆ3ï¼‰ç›¸å…³è®ºæ–‡æˆ–ä»£ç é“¾æ¥ï¼ˆå¦‚æœ‰ï¼‰ã€‚


<span class='anchor' id='publication'></span>

# ğŸ“ è®ºæ–‡åˆ—è¡¨ 

(* indicates equal contributions, â€  indicates corresponding author).

## æœŸåˆŠ
-  [Towards practical adam: Non-convexity, convergence theory, and mini-batch acceleration](https://www.jmlr.org/papers/v23/20-1438.html)<br> **Congliang Chen\***, Li Shen\*, Fangyu Zou\*, and Wei Liu, Journal of Machine Learning Research 23, no. 229 (2022): 1-47.

-   [Efficient-adam: Communication-efficient distributed adam](https://ieeexplore.ieee.org/abstract/document/10237319/) <br> **Congliang Chen**, Li Shen, Wei Liu, and Zhi-Quan Luo, IEEE Transactions on Signal Processing 71 (2023): 3257-3266.

-  [Quantized adam with error feedback](https://dl.acm.org/doi/abs/10.1145/3470890) <br>  **Congliang Chen**, Li Shen, Haozhi Huang, and Wei Liu, ACM Transactions on Intelligent Systems and Technology (TIST) 12, no. 5 (2021): 1-26.

- [A unified analysis of AdaGrad with weighted aggregation and momentum acceleration](https://ieeexplore.ieee.org/abstract/document/10149826/)<br> Li Shen, **Congliang Chen**, Fangyu Zou, Zequn Jie, Ju Sun, and Wei Liu, IEEE Transactions on Neural Networks and Learning Systems 35, no. 10 (2023): 14482-14490.

## ä¼šè®®


- [Communication efficient primal-dual algorithm for nonconvex nonsmooth distributed optimization](https://proceedings.mlr.press/v130/chen21c.html) <br>  **Congliang Chen**, Jiawei Zhang, Li Shen, Peilin Zhao, and Zhiquan Luo, In International conference on artificial intelligence and statistics, pp. 1594-1602. PMLR, 2021.

- [Adam-mini: Use fewer learning rates to gain more.](https://openreview.net/forum?id=iBExhaU3Lc)<br> Yushun Zhang\*, **Congliang Chen\***, Ziniu Li, Tian Ding, Chenwei Wu, Diederik P. Kingma, Yinyu Ye, Zhi-Quan Luo, and Ruoyu Sun,  In The Thirteenth International Conference on Learning Representations.


- [Preserving Diversity in Supervised Fine-Tuning of Large Language Models](https://openreview.net/forum?id=NQEe7B7bSw)<br> Ziniu Li, **Congliang Chen**, Tian Xu, Zeyu Qin, Jiancong Xiao, Zhi-Quan Luo, and Ruoyu Sun, In The Thirteenth International Conference on Learning Representations.

- [Why transformers need adam: A hessian perspective](https://proceedings.neurips.cc/paper_files/paper/2024/hash/ee0e45ff4de76cbfdf07015a7839f339-Abstract-Conference.html) <br> Yushun Zhang, **Congliang Chen**, Tian Ding, Ziniu Li, Ruoyu Sun, and Zhiquan Luo, Advances in neural information processing systems 37 (2024): 131786-131823.


- [Adam can converge without any modification on update rules](https://proceedings.neurips.cc/paper_files/paper/2022/hash/b6260ae5566442da053e5ab5d691067a-Abstract-Conference.html)<br> Yushun Zhang, **Congliang Chen**, Naichen Shi, Ruoyu Sun, and Zhi-Quan Luo, Advances in neural information processing systems 35 (2022): 28386-28399.

<span class='anchor' id='education'></span>

# ğŸ“– æ•™è‚²ç»å†
- *2018.08 - 2025.03*, åšå£«ï¼Œé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰ã€‚
- *2014.09 - 2018.06*, æœ¬ç§‘ï¼Œ åŒ—äº¬å¤§å­¦ã€‚


<span class='anchor' id='internship'></span>

# ğŸ’» å®ä¹ ç»å†
- *2019.07 - 2023.07*, è…¾è®¯AI Labï¼Œæ·±åœ³ï¼Œä¸­å›½ã€‚

<span class='anchor' id='service'></span>

# ğŸ« æœåŠ¡ç»å†
- ICML, NeurIPS, ICLR, ICCV, CVPRç­‰ä¼šè®®å®¡ç¨¿äºº.